“Computers have become a central field and laboratory instrument for much of our work, so we have an ethical duty to document how we change our data as it flows through silicon just as carefully as we document the operating parameters of a mass spectrometer or any other field or laboratory instrument.”  Marwick, Ben. 2025. ‘Is archaeology a science? Insights and imperatives from 10,000 articles and a year of reproducibility reviews’ Journal of Archaeological Science 180: 106281 DOI:  https://doi.org/10.1016/j.jas.2025.106281

​

This sentence connects back to the idea that previous readings have been saying throughout the weeks of taking this course. It reframes the act of writing and documenting code from a technical chore to an ethical duty. In my own personal work, I've experienced the struggle of trying to achieve results quickly and the discipline required to structure a project logically, comment code clearly, and manage space efficiently. This quote compares the care we take in documenting a physical experience with how it should be mirrored in our computational work. We hold scientists to a high standard of recording their methods, so we must apply the same standard to documenting how we use our code to manipulate and analyse data.

Working through this week's exercise helped me understand how messy and unpredictable computational work can be. My struggles to get the R notebooks to run, whether that was troubleshooting errors or trying to figure out why certain lines don't behave as expected, have reminded me that documenting at every step is essential. Without those notes, I wouldn't have been able to reproduce my own results and share them with others. This is what Marwick's thinking was advocating for. Our documentation standards should be the same as it would be for a scientist in a lab. 

For a history student, Unlike archeologists, they don't deal with physical samples that can be measured or graphed but we do work with data. If they approached materials like an archaeologist approaches artifacts, the implication would be great. They'd be far more deliberate about coding sources, keeping logs of searches, transcriptions, etc. That rigorous process would make historical research more transparent and open to extension, which could make it easier to teach students how historians actually think and not just the conclusions they want to reach. 

Another thing this week made me realize is that if we can reproduce analysis computationally, we could share our datasets or visualizations with a broader audience. People could test questions themselves whilst seeing the patterns we found, or even coming up with new interpretations. This would require historians to think more like data scientists to make history more participatory. ​

All in all, reflecting on my not-quite-successes like the problems I had when translating external ADS datasets into R, I'm reminded that reproducibility isn’t just about following instructions but it’s about persistence, experimentation, and learning from errors. For historians, acknowledging these messy parts of research could be just as valuable as sharing the polished final argument.

